---
title: WebPage Summarizer
emoji: ğŸŒ
colorFrom: blue
colorTo: green
sdk: streamlit
sdk_version: 1.28.0
app_file: app.py
pinned: false
license: mit
---

# ğŸŒ WebPage Summarizer

An intelligent web content summarization tool that extracts and condenses webpage information using advanced AI models.

## ğŸ“‹ Overview

This application creates concise, structured summaries of web content by leveraging state-of-the-art language models and robust web scraping techniques. Perfect for quickly understanding lengthy articles, blog posts, or documentation.

## âœ¨ Key Features

- **AI-Powered**: Powered by OpenAI's `gpt-4o-mini` model
- **Advanced Web Scraping**: Uses BeautifulSoup to handle static websites efficiently
- **Easy Interface**: Modern Streamlit web interface for immediate use
- **Smart Caching**: Repeated URLs use cached results for instant responses
- **Rate Limiting**: Fair usage limits with IP-based tracking
- **Security**: Robust IP extraction and request validation
- **Modular Architecture**: Clean separation of concerns for maintainability

## ğŸ› ï¸ Technology Stack

- **AI Model**: OpenAI GPT-4o-mini
- **Web Scraping**: BeautifulSoup, Python Requests  
- **Interface**: Streamlit
- **AI Integration**: OpenAI API
- **Caching**: File-based caching system
- **Rate Limiting**: IP-based rate limiting with persistent storage
- **Architecture**: Modular backend with clean separation of concerns

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Streamlit Web Interface                      â”‚
â”‚                        (app.py)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 UI Message Handler                            â”‚
â”‚              (ui/message_handler.py)                          â”‚
                                                                â”‚
â”‚  â€¢ Format user-facing messages                                â”‚
â”‚  â€¢ Handle error presentation                                  â”‚
â”‚  â€¢ Manage UI text and emojis                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend Services                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Rate Limiter   â”‚  â”‚   URL Cache     â”‚  â”‚ Webpage         â”‚â”‚
â”‚  â”‚  â€¢ IP tracking  â”‚  â”‚  â€¢ File-based   â”‚  â”‚ Summarizer      â”‚â”‚
â”‚  â”‚  â€¢ Cooldowns    â”‚  â”‚  â€¢ Fast lookup  â”‚  â”‚ â€¢ Orchestrates  â”‚â”‚
â”‚  â”‚  â€¢ Usage limits â”‚  â”‚  â€¢ TTL support  â”‚  â”‚   crawling      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â€¢ LLM summary   â”‚â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚  â”‚  IP Extractor   â”‚  â”‚  Web Crawler    â”‚                     â”‚
â”‚  â”‚  â€¢ Client IP    â”‚  â”‚  â€¢ BeautifulSoupâ”‚                     â”‚
â”‚  â”‚  â€¢ Header parse â”‚  â”‚  â€¢ Content cleanâ”‚                     â”‚
â”‚  â”‚  â€¢ Proxy supportâ”‚  â”‚  â€¢ Link extract â”‚                     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 External Services                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   OpenAI API    â”‚              â”‚  Web Content    â”‚         â”‚
â”‚  â”‚  (GPT-4o-mini)  â”‚              â”‚   (Target URLs) â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Responsibilities

- **UI Layer**: Handles all user-facing text, formatting, and presentation
- **Backend Services**: Pure business logic and data processing
- **Rate Limiting**: IP-based request throttling with persistent storage
- **Caching**: Fast retrieval of previously processed URLs
- **Web Crawling**: Content extraction and cleaning
- **IP Extraction**: Robust client identification for rate limiting

## ğŸš€ Usage

### Rate Limits
- **10 requests per hour** per user
- **25 requests per day** per user  
- **60 seconds cooldown** between requests
- **Cached results don't count** against your limits!

### How to Use
1. **Enter URL**: Paste the webpage URL you want to summarize
2. **Get Summary**: Click "Summarize" to receive an intelligent markdown summary

## ğŸ¯ Perfect For

- **News Articles**: Quickly digest lengthy news content
- **Research Papers**: Extract key points from academic materials
- **Documentation**: Summarize technical documentation
- **Business Reports**: Extract insights from corporate content

## ğŸš€ Running Locally

### Prerequisites
- Python 3.7 or higher
- pip (Python package installer)

### Installation Steps
1. **Clone the repository** (if not already done)
2. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```
3. **Set up environment variables** (create a `.env` file or export):
   ```bash
   export OPENAI_API_KEY="your-api-key-here"
   ```
4. **Run the application**:
   ```bash
   streamlit run app.py
   ```
5. **Access the web interface**: Open your browser to the URL shown in the terminal (typically `http://localhost:8501`)

## ğŸ”§ Setup Requirements

Set your OpenAI API key as an environment variable:
```bash
export OPENAI_API_KEY="your-api-key-here"
```

## ğŸ“ Examples

Try these sample URLs:
- https://en.wikipedia.org/wiki/Marie_Curie
- https://en.wikipedia.org/wiki/Artificial_intelligence

## ğŸ”§ Technical Details

### Backend Components

#### Rate Limiter (`backend/rate_limiter.py`)
- **RateLimitResult**: Data class with semantic limit types (COOLDOWN, HOURLY_LIMIT, DAILY_LIMIT)
- **IP-based tracking**: Persistent storage in `.rate_limits/` directory
- **Configurable limits**: Environment variable support for customization

#### Caching System (`backend/cache.py`)
- **File-based storage**: Efficient caching with TTL support
- **Cache directory**: `.cache/` for storing processed summaries
- **Performance optimization**: Instant responses for repeated URLs

#### Web Crawler (`backend/web_crawler.py`)
- **Content extraction**: BeautifulSoup-based HTML parsing
- **Content cleaning**: Removes scripts, styles, and irrelevant elements
- **Robust handling**: User-agent headers and error recovery

#### IP Extractor (`backend/ip_extractor.py`)
- **Multi-source IP detection**: Direct client IP and proxy headers
- **Proxy support**: Handles X-Forwarded-For, X-Real-IP, CF-Connecting-IP
- **Fallback handling**: Graceful degradation to localhost

#### Webpage Summarizer (`backend/webpage_summarizer.py`)
- **Orchestration**: Coordinates web crawling and LLM processing
- **Clean interface**: Single method for URL-to-summary conversion
- **Configurable model**: Support for different OpenAI models

### UI Components

#### Message Handler (`ui/message_handler.py`)
- **Separation of concerns**: All user-facing text isolated from backend
- **Semantic formatting**: Uses backend data structures for presentation
- **Consistent messaging**: Standardized error, success, and info messages

### Data Flow
1. **Request**: User submits URL via Streamlit interface
2. **Cache Check**: System checks for existing summary
3. **Rate Limiting**: IP-based validation with structured results
4. **Processing**: Web crawling and LLM summarization
5. **Caching**: Store result for future requests
6. **Response**: Formatted message with usage statistics

## ğŸ’¡ Tips

- Works best with content-rich pages (articles, blogs, documentation)
- Summaries include TL;DR sections for quick insights
- Cached results provide instant responses
- Rate limits reset hourly/daily for fair usage

## ğŸ“ Contact

**Developer:** [Daniela Veloz](https://www.linkedin.com/in/daniela-veloz/)

Connect on LinkedIn for questions, feedback, or collaboration opportunities!

## ğŸ”„ Auto-Sync

This repository automatically syncs with [Hugging Face Space](https://huggingface.co/spaces/daniela-veloz/WebSummarizer) on every push to main.


